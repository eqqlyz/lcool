/*
 * Copyright (C) 2014 James Cowgill
 *
 * LCool is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * LCool is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with LCool.  If not, see <http://www.gnu.org/licenses/>.
 */

#include <algorithm>
#include <boost/format.hpp>
#include <cctype>
#include <cstdio>
#include <istream>
#include <map>
#include <string>

#include "lexer.hpp"
#include "logger.hpp"
#include "smart_ptr.hpp"

namespace
{
	using namespace lcool;

	// List of keywords in lowercase
	const std::map<std::string, token_type> kw_mappings =
	{
		{ "case",       token_type::kw_case },
		{ "class",      token_type::kw_class },
		{ "else",       token_type::kw_else },
		{ "esac",       token_type::kw_esac },
		{ "fi",         token_type::kw_fi },
		{ "if",         token_type::kw_if },
		{ "in",         token_type::kw_in },
		{ "inherits",   token_type::kw_inherits },
		{ "isvoid",     token_type::kw_isvoid },
		{ "let",        token_type::kw_let },
		{ "loop",       token_type::kw_loop },
		{ "new",        token_type::kw_new },
		{ "not",        token_type::kw_not },
		{ "of",         token_type::kw_of },
		{ "pool",       token_type::kw_pool },
		{ "then",       token_type::kw_then },
		{ "while",      token_type::kw_while },
	};

	// Convert string to lowercase
	std::string str_tolower(const std::string& str)
	{
		std::string result;
		result.reserve(str.length());

		for (char c : str)
			result += std::tolower(c);

		return result;
	}
}

lcool::parse_error::parse_error(const lcool::location& loc, const std::string& msg)
	: runtime_error(msg), loc(loc)
{
}

lcool::parse_error::parse_error(const lcool::location& loc, const boost::format& msg)
	: runtime_error(msg.str()), loc(loc)
{
}

lexer::lexer(std::istream& input, lcool::shared_ptr<const std::string>& filename)
	: input(input), loc { filename, 1, 1 }, lookahead(EOF)
{
	// Consume first character
	consume_char();
}

lcool::token lexer::scan_token()
{
	// This function simply discards any comment tokens generated by scan_token_all
	token result;

	do
	{
		result = scan_token_all();
	}
	while (result.type == token_type::comment);

	return result;
}

lcool::token lexer::scan_token_all()
{
	// Skip leading whitespace
	while (isspace(lookahead))
		consume_char();

	// Initialize result
	token result;
	result.loc = loc;

	// Test based on first character
	int first = consume_char(result);

	switch (first)
	{
	case EOF:
		result.type = token_type::eof;
		break;

	// Symbols and comments
	case ';': result.type = token_type::semicolon; break;
	case ':': result.type = token_type::colon;     break;
	case ',': result.type = token_type::comma;     break;
	case '@': result.type = token_type::at;        break;
	case '.': result.type = token_type::dot;       break;
	case '{': result.type = token_type::lbraket;   break;
	case '}': result.type = token_type::rbraket;   break;
	case ')': result.type = token_type::rparen;    break;
	case '+': result.type = token_type::plus;      break;
	case '*': result.type = token_type::times;     break;
	case '/': result.type = token_type::divide;    break;
	case '~': result.type = token_type::negate;    break;

	case '<':
		// < <- <=
		if (lookahead == '-')
		{
			consume_char(result);
			result.type = token_type::assign;
		}
		else if (lookahead == '=')
		{
			consume_char(result);
			result.type = token_type::less_equal;
		}
		else
		{
			result.type = token_type::less;
		}

		break;

	case '=':
		// = =>
		if (lookahead == '>')
		{
			consume_char(result);
			result.type = token_type::case_arrow;
		}
		else
		{
			result.type = token_type::equal;
		}

		break;

	case '-':
		// - or single line comment
		if (lookahead == '-')
		{
			parse_comment_single();
			result.type = token_type::comment;
		}
		else
		{
			result.type = token_type::minus;
		}

		break;

	case '(':
		// ( or multi line comment
		if (lookahead == '*')
		{
			parse_comment_multi();
			result.type = token_type::comment;
		}
		else
		{
			result.type = token_type::lparen;
		}

	// Special tokens
	case '"':
		parse_string(result);
		break;

	default:
		// Test for special terminals
		if (isalpha(first))
		{
			parse_identifier(result);
		}
		else if (isdigit(first))
		{
			parse_integer(result);
		}
		else
		{
			throw parse_error(result.loc, boost::format("lexical error: %1%") % static_cast<char>(first));
		}
	}

	return result;
}

void lexer::parse_identifier(token& into)
{
	// Consume as many characters as possible
	while (isalnum(lookahead) || lookahead == '_')
		consume_char(into);

	// Determine token type
	auto iter = kw_mappings.find(str_tolower(into.value));
	if (iter != kw_mappings.end())
	{
		into.type = iter->second;
	}
	else if (into.value == "true" || into.value == "false")
	{
		into.type = token_type::boolean;
	}
	else if (islower(into.value[0]))
	{
		into.type = token_type::id;
	}
	else
	{
		into.type = token_type::type;
	}
}

void lexer::parse_string(token& into)
{
	int c;

	do
	{
		// Get next character
		c = consume_char(into);

		// Handle special characters
		if (c == '\\')
		{
			// Consume whatever the next character is
			consume_char(into);
		}
		else if (c == '\n')
		{
			throw parse_error(loc, "unexpected new line in string");
		}
		else if (c == EOF)
		{
			throw parse_error(loc, "unexpected end of file in string");
		}
	}
	while (c != '"');

	into.type = token_type::string;
}

void lexer::parse_integer(token& into)
{
	// Consume characters until the first non-digit
	while (isdigit(lookahead))
		consume_char(into);

	into.type = token_type::integer;
}

void lexer::parse_comment_single()
{
	// Consume everything until LF or EOF
	while (lookahead != '\n' && lookahead != EOF)
		consume_char();
}

void lexer::parse_comment_multi()
{
	// Consume characters while handling nested comments
	for (;;)
	{
		int c = consume_char();

		switch (c)
		{
		case EOF:
			throw parse_error(loc, "unterminated multi-line comment");

		case '(':
			if (lookahead == '*')
			{
				// Recurse to handle nested comment
				parse_comment_multi();
			}

			break;

		case '*':
			if (lookahead == ')')
			{
				// Consume braket and finish
				consume_char();
				return;
			}
		}
	}
}

int lexer::consume_char()
{
	// Read next character
	int prevLookahead = lookahead;
	lookahead = input.get();

	// Handle CRLF to LF conversion
	if (lookahead == '\r')
	{
		// Skip if the next character is LF
		if (input.peek() == '\n')
			input.get();

		lookahead = '\n';
	}

	// Update location pointer
	if (prevLookahead == '\n')
	{
		loc.line++;
		loc.column = 1;
	}
	else if (prevLookahead != EOF)
	{
		loc.column++;
	}

	return prevLookahead;
}

int lexer::consume_char(token& into)
{
	int c = consume_char();

	if (c != EOF)
		into.value += c;

	return c;
}
